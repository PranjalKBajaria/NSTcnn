{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import scipy.io.wavfile as wavfile\n",
    "import matplotlib.pyplot as plot\n",
    "import soundfile as sf\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioStuff:\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        \n",
    "    def audio_to_spectrogram(self):\n",
    "        audio, sr = librosa.load(self.filename)\n",
    "        D = np.abs(librosa.stft(audio))**2\n",
    "        audio= librosa.feature.melspectrogram(y=audio, sr=sr, S=D)\n",
    "        return (audio, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergeSpectrogram(spectrometer1, spectrometer2):\n",
    "        return (spectrogram1 + self.spectrogram2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(tensor):\n",
    "    #https://www.datacamp.com/community/tutorials/implementing-neural-style-transfer-using-tensorflow\n",
    "    \"\"\"\n",
    "    Computes the gram matrix of the input tensor, assuming it has exactly one layer.\n",
    "    :param input_tensor: input tensor\n",
    "    :return: gram matrix of the input tensor\n",
    "    \"\"\"\n",
    "    temp = tensor\n",
    "    temp = tf.squeeze(temp)\n",
    "    fun = tf.reshape(temp, [temp.shape[2], temp.shape[0]*temp.shape[1]])\n",
    "    result = tf.matmul(temp, temp, transpose_b=True)\n",
    "    gram = tf.expand_dims(result, axis=0)\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_c_func(mel_targets, mel_outputs):\n",
    "        return tf.losses.mean_squared_error(mel_targets, mel_outputs)\n",
    "        \n",
    "def loss_s_func(mel_targets, mel_outputs):\n",
    "        return tf.losses.mean_squared_error(gram_matrix(mel_targets), gram_matrix(mel_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_to_audio(spectrogram):\n",
    "    res = librosa.feature.inverse.mel_to_audio(spectrogram)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "# construction\n",
    "\n",
    "# I dont know if dense layers will be required have to look at the paper to see the model\n",
    "def model_audio_tranfer(content_spectrogram, style_spectrogram, combination_spectrogram):\n",
    "    # note according to keras lib sequential model is not beneficial here and vgg19 \n",
    "    # is for images and cannot be used for audio \n",
    "    # for better result add dense layers have 3 functions and name them blocks and then these block \n",
    "    # would have softmax and dense layers\n",
    "    # Flatten would be needed\n",
    "    # N_FILTERS = 4096\n",
    "    N_FILTERS = 256\n",
    "    x_1 = content_spectrogram\n",
    "    x_2 = style_spectrogram\n",
    "    x_3 = combination_spectrogram\n",
    "    _ , c_time, c_frequency, c_channel = tuple(content_spectrogram.shape)\n",
    "    _ , s_time, s_frequency, s_channel = tuple(style_spectrogram.shape)\n",
    "    _ , co_time, co_frequency, co_channel = tuple(combination_spectrogram.shape)\n",
    "    \n",
    "    \n",
    "    y_1 = tf.keras.layers.Conv2D(N_FILTERS, (3, 3), activation=\"relu\", \n",
    "                               strides = (2, 2), input_shape=(c_time, c_frequency, c_channel))(x_1)\n",
    "    y_2 = tf.keras.layers.Conv2D(N_FILTERS, (3, 3), activation = \"relu\", strides = (2, 2), \n",
    "                                 input_shape=(s_time, s_frequency, s_channel))(x_2)\n",
    "    \n",
    "    y_3 = tf.keras.layers.Conv2D(N_FILTERS, (3, 3), activation = \"relu\", strides = (2, 2), \n",
    "                                 input_shape=(co_time, co_frequency, co_channel))(x_3)\n",
    "    \n",
    "    return (y_1, y_2, y_3)\n",
    "#     model = tf.keras.models.Sequential([\n",
    "#     tf.keras.layers.Conv2D(N_FILTERS, (3,3), activation = \"relu\",\n",
    "#                           input_shape = (:,:,1)),\n",
    "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
    "#     tf.keras.layers.Conv2D(N_FILTERS, (3,3), activation = \"relu\", input_shape = (:,:,1))\n",
    "#     tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(128, activation = \"relu\"),\n",
    "#     tf.keras.layers.Dense(10, activation = \"softmax\"),\n",
    "#])\n",
    "\n",
    "#     model = tf.keras.models.Sequential()\n",
    "#     model.add(tf.keras.layers.Conv2D(N_FILTERS, (3, 3), activation='relu')) # layer for content\n",
    "#     model.add(tf.keras.layers.Conv2D(N_FILTERS, (3, 3), activation='relu')) # layer for style\n",
    "#     print(model.layers[1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(content_spectrogram, style_spectrogram, combination_spectrogram):\n",
    "    style_weight = 1e-6\n",
    "    content_weight = 2.5e-8\n",
    "    # Initialize the loss\n",
    "    loss = tf.zeros(shape=())\n",
    "    \n",
    "    #intialize the layers and there outputs\n",
    "    content_features, style_features, combination_features= \\\n",
    "    model_audio_tranfer(content_spectrogram, style_spectrogram, combination_spectrogram)\n",
    "    \n",
    "    # Add content loss\n",
    "\n",
    "    loss = loss + content_weight * loss_c_func(content_features, combination_features)\n",
    "    # Add style loss\n",
    "\n",
    "    sl = loss_s_func(style_features, combination_features)\n",
    "    loss += (style_weight / len(style_features)) * sl\n",
    "\n",
    "    # Add total variation loss\n",
    "    #loss += total_variation_weight * total_variation_loss(combination_image)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss_and_grads(content_spectrogram, style_spectrogram, combination_spectrogram):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(content_spectrogram, style_spectrogram, combination_spectrogram)\n",
    "    grads = tape.gradient(loss, combination_spectrogram)\n",
    "    return loss, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(\n",
    "    keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96\n",
    "    )\n",
    ")\n",
    "\n",
    "content_object = AudioStuff(\"vocals.wav\")\n",
    "style_object = AudioStuff(\"accompaniment.wav\")\n",
    "content_spectrogram, content_rate = content_object.audio_to_spectrogram()\n",
    "style_spectrogram, style_rate = style_object.audio_to_spectrogram()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s_time, s_frequency = style_spectrogram.shape\n",
    "c_time, c_frequency = content_spectrogram.shape\n",
    "\n",
    "\n",
    "# change 1 to the number of trainable batches ie the first dimension\n",
    "content_spectrogram = tf.reshape(content_spectrogram, [1, c_time , c_frequency, 1])\n",
    "style_spectrogram = tf.reshape(style_spectrogram, [1, s_time, s_frequency, 1])\n",
    "combination_spectrogram  =   tf.Variable(content_spectrogram)\n",
    "\n",
    "\n",
    "iterations = 100\n",
    "for i in range(1, iterations + 1):\n",
    "    #print(content_spectrogram)\n",
    "    loss, grads = compute_loss_and_grads(\n",
    "        content_spectrogram, style_spectrogram, combination_spectrogram\n",
    "    )\n",
    "    # works till here but comp will fail after this lol resource exhausted error (fix: change the hyperparameters)\n",
    "    optimizer.apply_gradients([(grads, combination_spectrogram)])\n",
    "    \n",
    "# might have to do tf.sqeeze and then tf.reshape because the dimension is different\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1293)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Only one segment is calculated since parameter NFFT (=256) >= signal length (=128).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "combination_spectrogram = tf.squeeze(combination_spectrogram)\n",
    "print(combination_spectrogram.shape)\n",
    "#colourband, frequency= combination_spectrogram.shape\n",
    "#combination_spectrogram = tf.reshape(combination_spectrogram, [colourband, frequency\n",
    "plot.subplot(212)\n",
    "plot.specgram(combination_spectrogram,Fs=style_rate)\n",
    "plot.xlabel('Time')\n",
    "plot.ylabel('Frequency')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_audio = spectrogram_to_audio(combination_spectrogram.numpy())\n",
    "sf.write(\"output.wav\", merge_audio, samplerate=style_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont run this\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    content_object = AudioStuff(\"vocals.wav\")\n",
    "    style_object = AudioStuff(\"accompaniment.wav\")\n",
    "    content_spectrogram, content_rate = content_object.audio_to_spectrogram()\n",
    "    style_spectrogram, style_rate = style_object.audio_to_spectrogram()\n",
    "    #print(content_spectrogram.shape)\n",
    "    #print(style_spectrogram)\n",
    "    object1 = SpectrogramStuff(content_spectrogram, style_spectrogram)\n",
    "    print(object1.MergeSpectrogram().shape)\n",
    "    #content_audio = spectrogram_to_audio(content_spectrogram)\n",
    "    merge_spectrogram = object1.MergeSpectrogram()\n",
    "    merge_audio = spectrogram_to_audio(merge_spectrogram)\n",
    "    #style_audio = spectrogram_to_audio(style_spectrogram)\n",
    "    wavfile.write(\"OUTPUT/outp3.wav\", style_rate, merge_audio)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn_model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNiVey80UiOqc2QN1g7ntWQ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Er4dNeDhf7de"},"source":["import numpy as np\n","import tensorflow as tf \n","import librosa\n","import pandas as pd\n","\n","class CNNModel:\n","  def __init__(self):\n","    std = np.sqrt(2) * np.sqrt(2.0 / ((N_CHANNELS + N_FILTERS) * 11))\n","    kernel = np.random.randn(1, 11, N_CHANNELS, N_FILTERS)*std\n","    kernel = tf.constant(kernel, name = \"kernel\", dtype = \"float32\")\n","    # not sure if this is the correct way to go for 1d networks... \n","    self.cnn1 = tf.nn.conv1d(input=1025,, kernel, stride=1, padding=1)\n","\n","\n","\n","\n","def get_style_model_and_losses(cnn, style_float,style_weight=style_weight, style_layers=style_layers_default): #STYLE WEIGHT\n","\t\t\n","\t\tcnn = copy.deepcopy(cnn)\n","\t\tstyle_losses = []\n","\t\tmodel = tf.keras.Sequential()  # the new Sequential module network\n","\t\tgram = GramMatrix()  # we need a gram module in order to compute style targets\n","\t\tif tf.test.is_gpu_available():  \n","\t\t\tmodel = model.cuda() # ---- Apparently there's no function for this command in Tensorflow and the gpu has to be pre-set in Tensorflow\n","      gram = gram.cuda()\n","\n","    # name = tf.Module('conv_1')\n","\t\t# model.add_module(name, cnn.cnn1)\n","\t\tif name in style_layers:\n","\t\t\ttarget_feature = model(style_float).clone()\n","\t\t\ttarget_feature_gram = gram(target_feature)\n","\t\t\tstyle_loss = StyleLoss(target_feature_gram, style_weight)\n","\t\t\t# model.add_module(\"style_loss_1\", style_loss)\n","\t\t\tstyle_losses.append(style_loss)\n","\n","\t\t#name = 'pool_1'\n","\t\t#model.add_module(name, cnn.pool1)\n","\n","\t\t'''name = 'fc_1'\n","\t\tmodel.add_module(name, cnn.fc1)\n","\t\tname = 'nl_9'\n","\t\tmodel.add_module(name, cnn.nl9)\n","\t\tname = 'fc_2'\n","\t\tmodel.add_module(name, cnn.fc2)'''\n","\n","\t\treturn model, style_losses\n","\n","\n","\tinput_float = content_float.clone()\n","\t#input_float = Variable(torch.randn(content_float.size())).type(torch.FloatTensor)\n","\n","\tlearning_rate_initial = 0.03\n","\n","\tdef get_input_param_optimizer(input_float):\n","\t\tinput_param = nn.Parameter(input_float.data)    # line------\n","\t\t#optimizer = optim.Adagrad([input_param], lr=learning_rate_initial, lr_decay=0.0001,weight_decay=0)\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate_initial, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\t\treturn input_param, optimizer\n","\n","\tnum_steps= 2500\n","\n","\tdef run_style_transfer(cnn, style_float, input_float, num_steps=num_steps, style_weight=style_weight): #STYLE WEIGHT, NUM_STEPS\n","\t\tprint('Building the style transfer model..')\n","\t\tmodel, style_losses= get_style_model_and_losses(cnn, style_float, style_weight)\n","\t\tinput_param, optimizer = get_input_param_optimizer(input_float)\n","\t\tprint('Optimizing..')\n","\t\trun = [0]\n","\n","\t\twhile run[0] <= num_steps:\n","\t\t\tdef closure():\n","            \t# correct the values of updated input image\n","\t\t\t\tinput_param.data = tf.clip_by_value(input_param.data, clip_value_min=0, clip_value_max=1)\n","\t\t\t\tmodel(input_param)\n","\t\t\t\tstyle_score = 0\n","\n","\t\t\t\tfor sl in style_losses:\n","\t\t\t\t\t#print('sl is ',sl,' style loss is ',style_score)\n","\t\t\t\t\tstyle_score += sl.backward()\n","\n","\t\t\t\trun[0] += 1\n","\t\t\t\tif run[0] % 100 == 0:\n","\t\t\t\t\tprint(\"run {}:\".format(run))\n","\t\t\t\t\tprint('Style Loss : {:8f}'.format(style_score.data[0])) #CHANGE 4->8 \n","\t\t\t\t\tprint()\n","\n","\t\t\t\treturn style_score\n","\n","\t\tinput_param.data = tf.clip_by_value(input_param.data, clip_value_min=0, clip_value_max=1)\n","\t\treturn input_param.data\n","\t\t\n","\toutput = run_style_transfer(cnn, style_float, input_float)\n","\n","\t#output = output.squeeze(0)\n","\toutput = output.squeeze(0) tf.test.is_gpu_available()\n","\toutput = output.numpy()\n","\t#print(output.shape)\n","\t#output = output.resize([1025,2500])\n","\t\n","\tN_FFT=2048\n","\ta = np.zeros_like(output)\n","\ta = np.exp(output) - 1\n","\n","\t# This code is supposed to do phase reconstruction\n","\tp = 2 * np.pi * np.random.random_sample(a.shape) - np.pi\n","\tfor i in range(500):\n","\t\tS = a * np.exp(1j*p)\n","\t\tx = librosa.istft(S)\n","\t\tp = np.angle(librosa.stft(x, N_FFT))\n","\n","\tOUTPUT_FILENAME = 'output1D_4096_iter'+str(num_steps)+'_c'+content_audio_name+'_s'+style_audio_name+'_sw'+str(style_weight)+'_k3s1p1.wav'\n","\tlibrosa.output.write_wav(OUTPUT_FILENAME, x, style_sr)\n","\n","\tprint('DONE...')"],"execution_count":null,"outputs":[]}]}